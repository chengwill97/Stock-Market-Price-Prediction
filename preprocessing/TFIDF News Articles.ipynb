{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  'year': 2016.0,\n",
    "  'month': 1.0,\n",
    "  'data': [{\n",
    "        'title': 'EXAMPLE TITLE',\n",
    "        'year': 2016.0,\n",
    "        'month': 1.0,\n",
    "        'day': 20.0,\n",
    "        'tfidf': [['word1', 0.051231], ['word2', 0.031231]],\n",
    "        'polarity': 0.1231241, \n",
    "        'subjectivity': 0.1241231\n",
    "      }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/willc97/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SPARK_LOCAL_IP'] = 'localhost'\n",
    "sc = pyspark.SparkContext(appName='News Articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)\n",
    "    \n",
    "def strtolower(s):\n",
    "    return s.lower()\n",
    "\n",
    "def analyze_news_articles(args):\n",
    "    input_folder, output_folder, articles_name = args\n",
    "    articles = os.path.join(input_folder, articles_name)\n",
    "    \n",
    "    month_df = pd.read_csv(articles)\n",
    "    print(\"Analyzing {name} which has {num_articles} articles\".format(name=articles_name, num_articles=len(month_df)))\n",
    "    \n",
    "    results = dict()\n",
    "    results['data'] = list()\n",
    "    \n",
    "    for day in range(1, 31+1):\n",
    "        day_df = month_df.where(month_df.day == day).dropna()\n",
    "        if len(day_df) == 0:\n",
    "            continue \n",
    "        print(\"Day {day}: {num_articles} articles\".format(day=day, num_articles=len(day_df)))\n",
    "        titles = list(day_df.title)\n",
    "        years = list(day_df.year)\n",
    "        months = list(day_df.month)\n",
    "        contents = list(day_df.content)\n",
    "        bloblist = list(map(tb, list(map(strtolower, contents))))\n",
    "        \n",
    "        results['year'] = years[0]\n",
    "        results['month'] = months[0]\n",
    "        \n",
    "        for i, blob in enumerate(bloblist):\n",
    "            scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "            sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            result = dict()\n",
    "            result['title'] = titles[i]\n",
    "            result['year'] = years[i]\n",
    "            result['month'] = months[i]\n",
    "            result['day'] = day\n",
    "\n",
    "            sentiment = tb(contents[i]).sentiment\n",
    "            result['polarity'] = sentiment.polarity\n",
    "            result['subjectivity'] = sentiment.subjectivity\n",
    "            \n",
    "            num_dist_words = len(sorted_words)\n",
    "            result['tdidf'] = sorted_words[:min(30, num_dist_words)]\n",
    "\n",
    "            results['data'].append(result)\n",
    "    \n",
    "    output_name = os.path.join(output_folder, articles_name.replace('.csv', '.json'))\n",
    "        \n",
    "    with open(output_name, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        \n",
    "    return (output_name, len(results['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'data/filtered/all-the-news/'\n",
    "output_folder = 'data/tfidf/all-the-news/'\n",
    "articles_names = os.listdir(input_folder)\n",
    "arguments = [(input_folder, output_folder, articles_name) for articles_name in articles_names]\n",
    "\n",
    "# print('Starting analysis')\n",
    "# process_articles_by_month = sc.parallelize(arguments, len(arguments)).map(analyze_news_articles)\n",
    "# collect_results_by_month = process_articles_by_month.collect()\n",
    "# print('Finished analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing articles_2016_12.csv which has 2886 articles\n",
      "Day 1: 107 articles\n",
      "Day 2: 140 articles\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-31f553d590d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyze_news_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-298e4e0009de>\u001b[0m in \u001b[0;36manalyze_news_articles\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0msorted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-298e4e0009de>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0msorted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-298e4e0009de>\u001b[0m in \u001b[0;36mtfidf\u001b[0;34m(word, blob, bloblist)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstrtolower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-298e4e0009de>\u001b[0m in \u001b[0;36midf\u001b[0;34m(word, bloblist)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_containing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-298e4e0009de>\u001b[0m in \u001b[0;36mn_containing\u001b[0;34m(word, bloblist)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mn_containing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbloblist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-298e4e0009de>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mn_containing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbloblist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/massive_data/lib/python3.6/site-packages/textblob/mixins.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, sub)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;34m'''Implements the `in` keyword like a Python string.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for argument in arguments[5:]:\n",
    "    print(analyze_news_articles(argument))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing articles_2017_07.csv which has 0 articles\n",
      "Analyzing articles_2015_03.csv which has 490 articles\n",
      "Day 1: 1 articles\n",
      "Day 2: 1 articles\n",
      "Analyzing articles_2016_09.csv which has 2963 articles\n",
      "Analyzing articles_2016_12.csv which has 2886 articles\n",
      "Day 1: 116 articles\n",
      "Day 1: 107 articles\n",
      "Day 4: 5 articles\n",
      "Analyzing articles_2017_11.csv which has 0 articles\n",
      "Analyzing articles_2016_01.csv which has 1766 articles\n",
      "Day 1: 72 articles\n",
      "Day 5: 3 articles\n",
      "Day 6: 20 articles\n",
      "Day 7: 10 articles\n",
      "Day 8: 12 articles\n",
      "Day 9: 21 articles\n",
      "Day 2: 31 articles\n",
      "Day 10: 28 articles\n",
      "Day 3: 57 articles\n",
      "Day 11: 18 articles\n",
      "Day 4: 65 articles\n",
      "Day 12: 22 articles\n",
      "Day 13: 15 articles\n",
      "Day 5: 61 articles\n",
      "Day 14: 15 articles\n",
      "Day 15: 16 articles\n",
      "Day 16: 13 articles\n",
      "Day 17: 22 articles\n",
      "Day 18: 23 articles\n",
      "Day 6: 63 articles\n",
      "Day 19: 25 articles\n",
      "Day 20: 27 articles\n",
      "Day 7: 61 articles\n",
      "Day 21: 10 articles\n",
      "Day 2: 136 articles\n",
      "Day 22: 16 articles\n",
      "Day 23: 20 articles\n",
      "Day 8: 53 articles\n",
      "Day 24: 14 articles\n",
      "Day 25: 22 articles\n",
      "Day 9: 44 articles\n",
      "Day 2: 140 articles\n",
      "Day 26: 21 articles\n",
      "Day 10: 65 articles\n",
      "Day 27: 24 articles\n",
      "Day 28: 12 articles\n",
      "Day 11: 63 articles\n",
      "Day 29: 15 articles\n",
      "Day 30: 20 articles\n",
      "Day 31: 19 articles\n",
      "Day 12: 55 articles\n",
      "Analyzing articles_2015_08.csv which has 45 articles\n",
      "Day 1: 13 articles\n",
      "Day 2: 3 articles\n",
      "Day 5: 2 articles\n",
      "Day 6: 25 articles\n",
      "Day 7: 1 articles\n",
      "Day 21: 1 articles\n",
      "Analyzing articles_2015_06.csv which has 677 articles\n",
      "Day 1: 34 articles\n",
      "Day 3: 78 articles\n",
      "Day 2: 22 articles\n",
      "Day 3: 30 articles\n",
      "Day 13: 64 articles\n",
      "Day 4: 36 articles\n",
      "Day 4: 68 articles\n",
      "Day 14: 60 articles\n",
      "Day 5: 32 articles\n",
      "Day 6: 20 articles\n",
      "Day 7: 5 articles\n",
      "Day 8: 25 articles\n",
      "Day 3: 74 articles\n",
      "Day 9: 27 articles\n",
      "Day 5: 86 articles\n",
      "Day 10: 22 articles\n",
      "Day 11: 41 articles\n",
      "Day 15: 64 articles\n",
      "Day 12: 25 articles\n",
      "Day 4: 84 articles\n",
      "Day 16: 40 articles\n",
      "Day 13: 14 articles\n",
      "Day 14: 22 articles\n",
      "Day 17: 59 articles\n",
      "Day 6: 118 articles\n",
      "Day 15: 14 articles\n",
      "Day 16: 28 articles\n",
      "Day 18: 64 articles\n",
      "Day 17: 33 articles\n",
      "Day 5: 86 articles\n",
      "Day 18: 28 articles\n",
      "Day 19: 58 articles\n",
      "Day 19: 32 articles\n",
      "Day 20: 64 articles\n",
      "Day 20: 17 articles\n",
      "Day 21: 16 articles\n",
      "Day 22: 29 articles\n",
      "Day 21: 61 articles\n",
      "Day 6: 103 articles\n",
      "Day 7: 100 articles\n",
      "Day 22: 55 articles\n",
      "Day 23: 28 articles\n",
      "Day 24: 11 articles\n",
      "Day 25: 13 articles\n",
      "Day 26: 38 articles\n",
      "Day 23: 20 articles\n",
      "Day 27: 15 articles\n",
      "Day 24: 39 articles\n",
      "Day 28: 1 articles\n",
      "Day 29: 4 articles\n",
      "Day 30: 15 articles\n",
      "Analyzing articles_2017_04.csv which has 3416 articles\n",
      "Day 1: 106 articles\n",
      "Day 25: 67 articles\n",
      "Day 8: 126 articles\n",
      "Day 7: 106 articles\n",
      "Day 26: 55 articles\n",
      "Day 27: 73 articles\n",
      "Day 8: 125 articles\n",
      "Day 28: 68 articles\n",
      "Day 2: 94 articles\n",
      "Day 9: 133 articles\n",
      "Day 29: 59 articles\n",
      "Day 9: 120 articles\n",
      "Day 3: 91 articles\n",
      "Day 30: 48 articles\n",
      "Day 10: 61 articles\n",
      "Day 31: 58 articles\n",
      "Analyzing articles_2015_05.csv which has 454 articles\n",
      "Day 1: 15 articles\n",
      "Day 2: 12 articles\n",
      "Day 11: 72 articles\n",
      "Day 3: 3 articles\n",
      "Day 4: 18 articles\n",
      "Day 5: 9 articles\n",
      "Day 6: 23 articles\n",
      "Day 10: 62 articles\n",
      "Day 7: 4 articles\n",
      "Day 4: 133 articles\n",
      "Day 8: 22 articles\n",
      "Day 9: 13 articles\n",
      "Day 10: 1 articles\n",
      "Day 11: 1 articles\n",
      "Day 12: 6 articles\n",
      "Day 13: 8 articles\n",
      "Day 14: 14 articles\n",
      "Day 12: 95 articles\n",
      "Day 11: 61 articles\n",
      "Day 15: 28 articles\n",
      "Day 16: 16 articles\n",
      "Day 17: 1 articles\n",
      "Day 18: 6 articles\n",
      "Day 12: 111 articles\n",
      "Day 19: 32 articles\n",
      "Day 20: 8 articles\n",
      "Day 21: 10 articles\n",
      "Day 22: 16 articles\n",
      "Day 13: 110 articles\n",
      "Day 23: 19 articles\n",
      "Day 24: 4 articles\n",
      "Day 25: 15 articles\n",
      "Day 26: 27 articles\n",
      "Day 27: 39 articles\n",
      "Day 28: 34 articles\n",
      "Day 29: 21 articles\n",
      "Day 14: 110 articles\n",
      "Day 30: 17 articles\n",
      "Day 31: 12 articles\n",
      "Analyzing articles_2015_01.csv which has 464 articles\n",
      "Day 1: 7 articles\n",
      "Day 2: 19 articles\n",
      "Day 5: 156 articles\n",
      "Day 13: 111 articles\n",
      "Day 3: 10 articles\n",
      "Day 5: 1 articles\n",
      "Day 6: 3 articles\n",
      "Day 7: 2 articles\n",
      "Day 8: 4 articles\n",
      "Day 9: 17 articles\n",
      "Day 10: 16 articles\n",
      "Day 11: 23 articles\n",
      "Day 12: 19 articles\n",
      "Day 15: 120 articles\n",
      "Day 13: 12 articles\n",
      "Day 14: 22 articles\n",
      "Day 15: 23 articles\n",
      "Day 16: 23 articles\n",
      "Day 14: 93 articles\n",
      "Day 17: 2 articles\n",
      "Day 18: 6 articles\n",
      "Day 19: 16 articles\n",
      "Day 20: 29 articles\n",
      "Day 21: 31 articles\n",
      "Day 22: 23 articles\n",
      "Day 23: 28 articles\n",
      "Day 15: 125 articles\n",
      "Day 24: 13 articles\n",
      "Day 16: 88 articles\n",
      "Day 25: 18 articles\n",
      "Day 26: 19 articles\n",
      "Day 27: 20 articles\n",
      "Day 6: 153 articles\n",
      "Day 28: 20 articles\n",
      "Day 29: 7 articles\n",
      "Day 30: 15 articles\n",
      "Day 31: 16 articles\n",
      "Analyzing articles_2016_03.csv which has 1829 articles\n",
      "Day 1: 70 articles\n",
      "Day 17: 78 articles\n",
      "Day 2: 54 articles\n",
      "Day 18: 81 articles\n",
      "Day 3: 59 articles\n",
      "Day 19: 90 articles\n",
      "Day 4: 61 articles\n",
      "Day 20: 94 articles\n",
      "Day 5: 38 articles\n",
      "Day 16: 128 articles\n",
      "Day 6: 62 articles\n",
      "Day 7: 169 articles\n",
      "Day 21: 111 articles\n",
      "Day 7: 61 articles\n",
      "Day 8: 62 articles\n",
      "Day 22: 107 articles\n",
      "Day 17: 70 articles\n",
      "Day 9: 66 articles\n",
      "Day 18: 70 articles\n",
      "Day 10: 60 articles\n",
      "Day 23: 128 articles\n",
      "Day 19: 67 articles\n",
      "Day 11: 60 articles\n",
      "Day 20: 93 articles\n",
      "Day 12: 53 articles\n",
      "Day 24: 64 articles\n",
      "Day 13: 73 articles\n",
      "Day 25: 84 articles\n",
      "Day 21: 100 articles\n",
      "Day 8: 122 articles\n",
      "Day 14: 50 articles\n",
      "Day 26: 113 articles\n",
      "Day 15: 61 articles\n",
      "Day 16: 61 articles\n",
      "Day 22: 97 articles\n",
      "Day 17: 66 articles\n",
      "Day 18: 50 articles\n",
      "Day 27: 83 articles\n",
      "Day 19: 54 articles\n",
      "Day 23: 110 articles\n",
      "Day 20: 47 articles\n",
      "Day 21: 63 articles\n",
      "Day 24: 58 articles\n",
      "Day 28: 103 articles\n",
      "Day 22: 64 articles\n",
      "Day 25: 66 articles\n",
      "Day 29: 98 articles\n",
      "Day 9: 100 articles\n",
      "Day 26: 69 articles\n",
      "Day 23: 60 articles\n",
      "Day 27: 93 articles\n",
      "Day 24: 62 articles\n",
      "Day 30: 112 articles\n",
      "Day 25: 69 articles\n",
      "Day 26: 51 articles\n",
      "Day 27: 51 articles\n",
      "Day 28: 89 articles\n",
      "Day 28: 60 articles\n",
      "Analyzing articles_2016_11.csv which has 2591 articles\n",
      "Day 1: 74 articles\n",
      "Day 10: 127 articles\n",
      "Day 29: 67 articles\n",
      "Day 2: 42 articles\n",
      "Day 29: 93 articles\n",
      "Day 3: 61 articles\n",
      "Day 30: 53 articles\n",
      "Day 4: 80 articles\n",
      "Day 30: 108 articles\n",
      "Day 31: 61 articles\n",
      "Day 5: 51 articles\n",
      "Analyzing articles_2015_11.csv which has 4 articles\n",
      "Day 16: 2 articles\n",
      "Day 24: 1 articles\n",
      "Day 26: 1 articles\n",
      "Analyzing articles_2017_03.csv which has 3414 articles\n",
      "Day 1: 124 articles\n",
      "Day 6: 50 articles\n",
      "Day 7: 118 articles\n",
      "Day 31: 67 articles\n",
      "Analyzing articles_2017_05.csv which has 2539 articles\n",
      "Day 1: 82 articles\n",
      "Day 8: 75 articles\n",
      "Day 2: 117 articles\n",
      "Day 2: 80 articles\n",
      "Day 11: 150 articles\n",
      "Day 3: 84 articles\n",
      "Day 9: 128 articles\n",
      "Day 3: 140 articles\n",
      "Day 4: 81 articles\n",
      "Day 5: 102 articles\n",
      "Day 10: 101 articles\n",
      "Day 6: 62 articles\n",
      "Day 7: 74 articles\n",
      "Day 11: 110 articles\n",
      "Day 12: 160 articles\n",
      "Day 4: 81 articles\n",
      "Day 8: 80 articles\n",
      "Day 5: 71 articles\n",
      "Day 12: 73 articles\n",
      "Day 9: 87 articles\n",
      "Day 13: 73 articles\n",
      "Day 6: 137 articles\n",
      "Day 10: 101 articles\n",
      "Day 14: 94 articles\n",
      "Day 11: 75 articles\n",
      "Day 12: 86 articles\n",
      "Day 15: 117 articles\n",
      "Day 7: 114 articles\n",
      "Day 13: 67 articles\n",
      "Day 13: 187 articles\n",
      "Day 14: 73 articles\n",
      "Day 16: 45 articles\n",
      "Day 15: 77 articles\n",
      "Day 8: 130 articles\n",
      "Day 17: 103 articles\n",
      "Day 16: 97 articles\n",
      "Day 18: 115 articles\n",
      "Day 17: 83 articles\n",
      "Day 18: 92 articles\n",
      "Day 9: 149 articles\n",
      "Day 19: 63 articles\n",
      "Day 19: 94 articles\n",
      "Day 20: 78 articles\n",
      "Day 14: 180 articles\n",
      "Day 20: 73 articles\n",
      "Day 21: 104 articles\n",
      "Day 21: 55 articles\n",
      "Day 22: 90 articles\n",
      "Day 10: 112 articles\n",
      "Day 22: 108 articles\n",
      "Day 23: 88 articles\n",
      "Day 24: 75 articles\n",
      "Day 23: 118 articles\n",
      "Day 11: 86 articles\n",
      "Day 25: 87 articles\n",
      "Day 15: 97 articles\n",
      "Day 26: 88 articles\n",
      "Day 12: 95 articles\n",
      "Day 24: 79 articles\n",
      "Day 27: 85 articles\n",
      "Day 25: 101 articles\n",
      "Day 16: 59 articles\n",
      "Day 13: 118 articles\n",
      "Day 28: 65 articles\n",
      "Day 17: 106 articles\n",
      "Day 26: 65 articles\n",
      "Day 29: 68 articles\n",
      "Day 27: 65 articles\n",
      "Day 28: 89 articles\n",
      "Day 30: 86 articles\n",
      "Day 18: 83 articles\n",
      "Day 31: 102 articles\n",
      "Day 29: 119 articles\n",
      "Day 19: 122 articles\n",
      "Day 14: 107 articles\n",
      "Analyzing articles_2016_06.csv which has 2596 articles\n",
      "Day 1: 75 articles\n",
      "Day 2: 82 articles\n",
      "Day 30: 92 articles\n",
      "Day 15: 137 articles\n",
      "Day 3: 81 articles\n",
      "Analyzing articles_2015_02.csv which has 280 articles\n",
      "Day 1: 16 articles\n",
      "Day 2: 6 articles\n",
      "Day 3: 5 articles\n",
      "Day 4: 10 articles\n",
      "Day 5: 19 articles\n",
      "Day 4: 55 articles\n",
      "Day 6: 8 articles\n",
      "Day 7: 14 articles\n",
      "Day 20: 120 articles\n",
      "Day 8: 4 articles\n",
      "Day 9: 6 articles\n",
      "Day 10: 16 articles\n",
      "Day 11: 8 articles\n",
      "Day 12: 5 articles\n",
      "Day 13: 13 articles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 5: 60 articles\n",
      "Day 14: 15 articles\n",
      "Day 15: 2 articles\n",
      "Day 16: 17 articles\n",
      "Day 6: 75 articles\n",
      "Day 17: 1 articles\n",
      "Day 18: 9 articles\n",
      "Day 19: 20 articles\n",
      "Day 20: 15 articles\n",
      "Day 21: 17 articles\n",
      "Day 22: 2 articles\n",
      "Day 23: 1 articles\n",
      "Day 24: 2 articles\n",
      "Day 25: 4 articles\n",
      "Day 26: 9 articles\n",
      "Day 27: 23 articles\n",
      "Day 7: 79 articles\n",
      "Day 28: 13 articles\n",
      "Analyzing articles_2017_01.csv which has 3655 articles\n",
      "Day 1: 57 articles\n",
      "Day 16: 109 articles\n",
      "Day 2: 107 articles\n",
      "Day 21: 110 articles\n",
      "Day 8: 83 articles\n",
      "Day 9: 79 articles\n",
      "Day 22: 86 articles\n",
      "Day 3: 119 articles\n",
      "Day 17: 124 articles\n",
      "Day 10: 92 articles\n",
      "Day 23: 61 articles\n",
      "Day 11: 52 articles\n",
      "Day 24: 95 articles\n",
      "Day 12: 55 articles\n",
      "Day 18: 64 articles\n",
      "Day 13: 79 articles\n",
      "Day 25: 119 articles\n",
      "Day 4: 151 articles\n",
      "Day 19: 69 articles\n",
      "Day 14: 94 articles\n",
      "Day 20: 120 articles\n",
      "Day 26: 97 articles\n",
      "Day 15: 81 articles\n",
      "Day 16: 92 articles\n",
      "Day 5: 116 articles\n",
      "Day 27: 112 articles\n",
      "Day 17: 117 articles\n",
      "Day 21: 118 articles\n",
      "Day 6: 142 articles\n",
      "Day 28: 91 articles\n",
      "Day 18: 78 articles\n",
      "Day 19: 64 articles\n",
      "Day 29: 71 articles\n",
      "Day 22: 117 articles\n",
      "Day 20: 101 articles\n",
      "Day 7: 95 articles\n",
      "Day 30: 59 articles\n",
      "Analyzing articles_2017_02.csv which has 3227 articles\n",
      "Day 1: 130 articles\n",
      "Day 21: 118 articles\n",
      "Day 8: 77 articles\n",
      "Day 23: 102 articles\n",
      "Day 9: 150 articles\n",
      "Day 24: 109 articles\n",
      "Day 22: 102 articles\n",
      "Day 2: 122 articles\n",
      "Day 25: 75 articles\n",
      "Day 26: 83 articles\n",
      "Day 23: 97 articles\n",
      "Day 3: 172 articles\n",
      "Day 10: 149 articles\n",
      "Day 27: 86 articles\n",
      "Day 24: 136 articles\n",
      "Day 28: 137 articles\n",
      "Day 25: 67 articles\n",
      "Day 26: 84 articles\n",
      "Day 4: 109 articles\n",
      "Day 29: 132 articles\n",
      "Day 11: 128 articles\n",
      "Day 27: 109 articles\n",
      "Day 5: 81 articles\n",
      "Day 28: 106 articles\n",
      "Day 30: 102 articles\n",
      "Day 6: 123 articles\n",
      "Day 31: 149 articles\n",
      "Day 29: 100 articles\n",
      "Day 12: 136 articles\n",
      "Day 7: 138 articles\n",
      "Day 30: 103 articles\n",
      "Analyzing articles_2015_09.csv which has 2 articles\n",
      "Day 2: 1 articles\n",
      "Day 24: 1 articles\n",
      "Analyzing articles_2016_10.csv which has 2501 articles\n",
      "Day 1: 68 articles\n",
      "Day 2: 79 articles\n",
      "Day 8: 137 articles\n",
      "Analyzing articles_2016_05.csv which has 1822 articles\n",
      "Day 1: 60 articles\n",
      "Day 13: 144 articles\n",
      "Day 3: 97 articles\n",
      "Day 2: 80 articles\n",
      "Day 4: 91 articles\n",
      "Day 3: 63 articles\n",
      "Day 14: 85 articles\n",
      "Day 4: 33 articles\n",
      "Day 5: 70 articles\n",
      "Day 5: 107 articles\n",
      "Day 15: 102 articles\n",
      "Day 6: 88 articles\n",
      "Day 7: 52 articles\n",
      "Day 9: 22 articles\n",
      "Day 10: 50 articles\n",
      "Day 6: 107 articles\n",
      "Day 9: 109 articles\n",
      "Day 16: 115 articles\n",
      "Day 11: 36 articles\n",
      "Day 12: 68 articles\n",
      "Day 13: 63 articles\n",
      "Day 14: 33 articles\n",
      "Day 7: 112 articles\n",
      "Day 15: 52 articles\n",
      "Day 16: 74 articles\n",
      "Day 10: 134 articles\n",
      "Day 17: 82 articles\n",
      "Day 17: 142 articles\n",
      "Day 8: 102 articles\n",
      "Day 18: 62 articles\n",
      "Day 19: 82 articles\n",
      "Day 11: 86 articles\n",
      "Day 9: 62 articles\n",
      "Day 20: 88 articles\n",
      "Day 12: 82 articles\n",
      "Day 21: 38 articles\n",
      "Day 10: 107 articles\n",
      "Day 22: 54 articles\n",
      "Day 23: 68 articles\n",
      "Day 18: 126 articles\n",
      "Day 13: 126 articles\n",
      "Day 24: 72 articles\n",
      "Day 25: 64 articles\n",
      "Day 26: 60 articles\n",
      "Day 11: 114 articles\n",
      "Day 27: 85 articles\n",
      "Day 28: 35 articles\n",
      "Day 29: 54 articles\n",
      "Day 14: 125 articles\n",
      "Day 30: 63 articles\n",
      "Day 19: 141 articles\n",
      "Day 12: 100 articles\n",
      "Day 31: 71 articles\n",
      "Analyzing articles_2016_02.csv which has 1706 articles\n",
      "Day 1: 69 articles\n",
      "Day 13: 106 articles\n",
      "Day 2: 60 articles\n",
      "Day 15: 124 articles\n",
      "Day 3: 60 articles\n",
      "Day 4: 74 articles\n",
      "Day 14: 124 articles\n",
      "Day 5: 50 articles\n",
      "Day 6: 63 articles\n",
      "Day 16: 111 articles\n",
      "Day 20: 143 articles\n",
      "Day 7: 48 articles\n",
      "Day 8: 61 articles\n",
      "Day 15: 91 articles\n",
      "Day 9: 62 articles\n",
      "Day 10: 63 articles\n",
      "Day 16: 66 articles\n",
      "Day 11: 64 articles\n",
      "Day 17: 105 articles\n",
      "Day 12: 61 articles\n",
      "Day 13: 61 articles\n",
      "Day 17: 123 articles\n",
      "Day 14: 50 articles\n",
      "Day 21: 89 articles\n",
      "Day 15: 57 articles\n",
      "Day 18: 88 articles\n",
      "Day 16: 63 articles\n",
      "Day 19: 51 articles\n",
      "Day 22: 71 articles\n",
      "Day 20: 91 articles\n",
      "Day 23: 113 articles\n",
      "Day 18: 76 articles\n",
      "Day 21: 72 articles\n",
      "Day 19: 93 articles\n",
      "Day 22: 49 articles\n",
      "Day 23: 54 articles\n",
      "Day 24: 118 articles\n",
      "Day 24: 16 articles\n",
      "Day 25: 33 articles\n",
      "Day 26: 92 articles\n",
      "Day 17: 60 articles\n",
      "Day 27: 100 articles\n",
      "Day 18: 60 articles\n",
      "Day 20: 113 articles\n",
      "Day 19: 67 articles\n",
      "Day 25: 125 articles\n",
      "Day 20: 51 articles\n",
      "Day 28: 90 articles\n",
      "Day 21: 49 articles\n",
      "Day 22: 63 articles\n",
      "Day 21: 131 articles\n",
      "Day 23: 61 articles\n",
      "Day 29: 44 articles\n",
      "Day 30: 14 articles\n",
      "Day 31: 69 articles\n",
      "Day 26: 139 articles\n",
      "Analyzing articles_2017_06.csv which has 1657 articles\n",
      "Day 1: 69 articles\n",
      "Day 2: 105 articles\n",
      "Day 3: 71 articles\n",
      "Day 22: 123 articles\n",
      "Day 24: 59 articles\n",
      "Day 4: 64 articles\n",
      "Day 25: 61 articles\n",
      "Day 5: 78 articles\n",
      "Day 23: 104 articles\n",
      "Day 6: 82 articles\n",
      "Day 27: 135 articles\n",
      "Day 26: 57 articles\n",
      "Day 7: 82 articles\n",
      "Day 27: 54 articles\n",
      "Day 28: 39 articles\n",
      "Day 8: 99 articles\n",
      "Day 24: 146 articles\n",
      "Day 29: 59 articles\n",
      "Day 28: 104 articles\n",
      "Day 9: 100 articles\n",
      "Analyzing articles_2015_12.csv which has 70 articles\n",
      "Day 2: 1 articles\n",
      "Day 6: 1 articles\n",
      "Day 8: 1 articles\n",
      "Day 11: 1 articles\n",
      "Day 17: 1 articles\n",
      "Day 21: 1 articles\n",
      "Day 22: 1 articles\n",
      "Day 23: 1 articles\n",
      "Day 24: 1 articles\n",
      "Day 28: 1 articles\n",
      "Day 29: 1 articles\n",
      "Day 30: 7 articles\n",
      "Day 31: 52 articles\n",
      "Day 10: 83 articles\n",
      "Day 29: 98 articles\n",
      "Analyzing articles_2017_10.csv which has 0 articles\n",
      "Analyzing articles_2017_09.csv which has 0 articles\n",
      "Analyzing articles_2016_07.csv which has 2813 articles\n",
      "Day 1: 134 articles\n",
      "Day 11: 69 articles\n",
      "Day 12: 74 articles\n",
      "Day 25: 96 articles\n",
      "Day 13: 88 articles\n",
      "Day 30: 108 articles\n",
      "Day 2: 60 articles\n",
      "Day 3: 71 articles\n",
      "Day 26: 93 articles\n",
      "Day 14: 88 articles\n",
      "Day 4: 113 articles\n",
      "Day 15: 83 articles\n",
      "Day 31: 130 articles\n",
      "Day 5: 98 articles\n",
      "Day 27: 103 articles\n",
      "Day 16: 99 articles\n",
      "Day 6: 81 articles\n",
      "Day 17: 80 articles\n",
      "Day 28: 117 articles\n",
      "Day 7: 97 articles\n",
      "Day 18: 71 articles\n",
      "Analyzing articles_2016_08.csv which has 3058 articles\n",
      "Day 1: 79 articles\n",
      "Day 19: 88 articles\n",
      "Day 2: 119 articles\n",
      "Day 8: 111 articles\n",
      "Day 20: 69 articles\n",
      "Analyzing articles_2017_12.csv which has 0 articles\n",
      "Day 3: 95 articles\n",
      "Day 9: 79 articles\n",
      "Day 21: 15 articles\n",
      "Day 4: 120 articles\n",
      "Day 10: 75 articles\n",
      "Day 11: 101 articles\n",
      "Day 5: 112 articles\n",
      "Day 12: 98 articles\n",
      "Day 6: 76 articles\n",
      "Day 7: 65 articles\n",
      "Day 8: 97 articles\n",
      "Day 13: 113 articles\n",
      "Day 9: 109 articles\n",
      "Day 14: 91 articles\n",
      "Day 10: 101 articles\n",
      "Day 15: 98 articles\n",
      "Day 11: 114 articles\n",
      "Day 16: 72 articles\n",
      "Day 17: 83 articles\n",
      "Day 12: 100 articles\n",
      "Day 18: 94 articles\n",
      "Day 13: 81 articles\n",
      "Day 14: 82 articles\n",
      "Day 19: 87 articles\n",
      "Day 15: 96 articles\n",
      "Day 20: 99 articles\n",
      "Day 16: 98 articles\n",
      "Day 17: 66 articles\n",
      "Day 21: 108 articles\n",
      "Day 18: 116 articles\n",
      "Day 22: 102 articles\n",
      "Day 19: 107 articles\n",
      "Day 23: 80 articles\n",
      "Day 20: 40 articles\n",
      "Day 24: 68 articles\n",
      "Day 21: 81 articles\n",
      "Day 22: 221 articles\n",
      "Day 25: 87 articles\n",
      "Day 26: 84 articles\n",
      "Day 27: 81 articles\n",
      "Day 28: 98 articles\n",
      "Day 29: 100 articles\n",
      "Day 30: 76 articles\n",
      "Day 23: 125 articles\n",
      "Day 31: 74 articles\n",
      "Day 24: 99 articles\n",
      "Day 25: 86 articles\n",
      "Day 26: 114 articles\n",
      "Day 27: 76 articles\n",
      "Day 28: 72 articles\n",
      "Day 29: 95 articles\n",
      "Day 30: 108 articles\n",
      "Day 31: 108 articles\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pool.map(analyze_news_articles, arguments[5:])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\r\n",
      "drwxrwxr-x 3 willc97 4096 Dec  9 16:33 \u001b[0m\u001b[01;34mfiltered\u001b[0m/\r\n",
      "drwxrwxr-x 4 willc97 4096 Dec  8 20:34 \u001b[01;34mraw\u001b[0m/\r\n",
      "drwxrwxr-x 3 willc97 4096 Dec 10 12:59 \u001b[01;34mtfidf\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ll data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
